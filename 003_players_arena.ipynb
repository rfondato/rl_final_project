{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adf8ee94",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c109c1",
   "metadata": {},
   "source": [
    "# Importar entorno y familiarizarse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f0adfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from boardgame2 import ReversiEnv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56b52e1",
   "metadata": {},
   "source": [
    "# Crear 3 tipos de jugador\n",
    "- Random: Selecciona uniformemente una de las acciones válidas\n",
    "- Greedy: Selecciona la acción que le da más ganancia inmediata (cantidad de piezas que come). Si hay más de una acción que da máxima ganancia samplear uniformemente entre ellas\n",
    "- Optimum (solo para 4x4): Usando resultados de la PI optima obtenida por policy iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b916ce4c",
   "metadata": {},
   "source": [
    "Tener en cuenta que:\n",
    "- ReversiEnv tiene los métodos get_valid y next_step y no es necesario mantener el estado del entorno\n",
    "- env.PASS ([-1,  0]) es una acción valida posible y debería hacerse cuando no get_valid devuelve una matriz de ceros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f077531",
   "metadata": {},
   "source": [
    "Para el optimo en 4x4 bajar usar la PI obtenida en la notebook anterior guardado en /mdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9819f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a30380c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedyPlayer():\n",
    "    def __init__(self, player=1, board_shape=None, env=None, flatten_action=False):\n",
    "        if (env is None) and (board_shape is None):\n",
    "            print(\"board_shape and env can't be both None\")\n",
    "        if env is None:\n",
    "            env = ReversiEnv(board_shape=board_shape)\n",
    "        self.env = env\n",
    "        self.player = player # player number. 1 o -1\n",
    "        self.flatten_action = flatten_action\n",
    "        self.board_shape = self.env.board.shape[0]\n",
    "    \n",
    "    def predict(self, board):\n",
    "        # Implementar\n",
    "        # Tiene que devoler la acción en la que come más piezas.\n",
    "        # A igualdad de piezas comidas, samplear uniformemente\n",
    "        \n",
    "        state = (board, self.player)\n",
    "        \n",
    "        valid_board = self.env.get_valid(state)\n",
    "        valid_actions = np.argwhere(valid_board)\n",
    "        \n",
    "        if (len(valid_actions) == 0):\n",
    "            action = self.env.PASS\n",
    "        else:\n",
    "            actions_opponent_pieces = dict()\n",
    "\n",
    "            for a in valid_actions:\n",
    "                a = tuple(a)\n",
    "                next_state = self.env.get_next_state(state, a)[0]\n",
    "                actions_opponent_pieces[a] = len(next_state[next_state == -self.player])\n",
    "\n",
    "            min_opp_pieces = min(actions_opponent_pieces.values())\n",
    "            greedy_actions = [a for a, p in actions_opponent_pieces.items() if p == min_opp_pieces]\n",
    "\n",
    "            action = random.choice(greedy_actions)\n",
    "        \n",
    "        if self.flatten_action:\n",
    "            return action[0] * self.board_shape + action[1]\n",
    "        else:\n",
    "            return action\n",
    "        \n",
    "class RandomPlayer():\n",
    "    def __init__(self, player=1, board_shape=None, env=None, flatten_action=False):\n",
    "        if (env is None) and (board_shape is None):\n",
    "            print(\"board_shape and env can't be both None\")\n",
    "        if env is None:\n",
    "            env = ReversiEnv(board_shape=board_shape)\n",
    "        self.env = env\n",
    "        self.player = player\n",
    "        self.flatten_action = flatten_action\n",
    "        self.board_shape = self.env.board.shape[0]\n",
    "    \n",
    "    def predict(self, board):\n",
    "        # Muestrea aleatoriamente las acciones válidas\n",
    "        # Puede usar la función creada en la notebook anterior\n",
    "        \n",
    "        state = (board, self.player)\n",
    "        \n",
    "        valid_board = self.env.get_valid(state)\n",
    "        valid_actions = np.argwhere(valid_board)\n",
    "        \n",
    "        if (len(valid_actions) == 0):\n",
    "            action = self.env.PASS\n",
    "        else:\n",
    "            action = tuple(random.choice(valid_actions))\n",
    "        \n",
    "        if self.flatten_action:\n",
    "            return action[0] * self.board_shape + action[1]\n",
    "        else:\n",
    "            return action\n",
    "        \n",
    "\n",
    "class DictPolicyPlayer():\n",
    "    def __init__(self, player=1, board_shape=4, env=None, flatten_action=False, dict_folder='mdp/pi_mdp.npy'):\n",
    "        self.pi_dict = np.load(dict_folder, allow_pickle=True).item()\n",
    "        if env is None:\n",
    "            env = ReversiEnv(board_shape=board_shape)\n",
    "        self.env = env\n",
    "        self.player = player\n",
    "        self.flatten_action = flatten_action\n",
    "        self.board_shape = board_shape\n",
    "    \n",
    "    def predict(self, board):\n",
    "        # Elegir la acción optima y devolverla\n",
    "        \n",
    "        board = tuple(board.flatten() * self.player)         \n",
    "        \n",
    "        if (board in self.pi_dict):\n",
    "            action = self.pi_dict[board]\n",
    "        else:\n",
    "            action = self.env.PASS\n",
    "        \n",
    "        if self.flatten_action:\n",
    "            return action[0] * self.board_shape + action[1]\n",
    "        else:\n",
    "            return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "897881dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = GreedyPlayer(player=1, board_shape=4)\n",
    "rp = RandomPlayer(player=1, board_shape=4)\n",
    "pp = DictPolicyPlayer(player=1, board_shape=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f18b57",
   "metadata": {},
   "source": [
    "# Verificar que el pass funciona OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b47fdb7-4f90-4fda-9a11-af7800436f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random action:  [-1  0]\n",
      "Greedy action:  [-1  0]\n",
      "Optimum action:  [-1  0]\n",
      "\n",
      "Random action:  [-1  0]\n",
      "Greedy action:  [-1  0]\n",
      "Optimum action:  [-1  0]\n",
      "\n",
      "Random action:  [-1  0]\n",
      "Greedy action:  [-1  0]\n",
      "Optimum action:  [-1  0]\n",
      "\n",
      "Random action:  [-1  0]\n",
      "Greedy action:  [-1  0]\n",
      "Optimum action:  [-1  0]\n",
      "\n",
      "Random action:  [-1  0]\n",
      "Greedy action:  [-1  0]\n",
      "Optimum action:  [-1  0]\n",
      "\n",
      "Random action:  [-1  0]\n",
      "Greedy action:  [-1  0]\n",
      "Optimum action:  [-1  0]\n",
      "\n",
      "Random action:  [-1  0]\n",
      "Greedy action:  [-1  0]\n",
      "Optimum action:  [-1  0]\n",
      "\n",
      "Random action:  [-1  0]\n",
      "Greedy action:  [-1  0]\n",
      "Optimum action:  [-1  0]\n",
      "\n",
      "Random action:  [-1  0]\n",
      "Greedy action:  [-1  0]\n",
      "Optimum action:  [-1  0]\n",
      "\n",
      "Random action:  [-1  0]\n",
      "Greedy action:  [-1  0]\n",
      "Optimum action:  [-1  0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Creo un tablero invalido para testear el pass en todas las estrategias\n",
    "invalid_board = np.array([\n",
    "    [ 1,  0,  0,  0],\n",
    "    [ 0,  0,  0,  0],\n",
    "    [ 0,  0,  0,  0],\n",
    "    [ 0,  0,  0, -1]]\n",
    ")\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"Random action: \", rp.predict(invalid_board))\n",
    "    print(\"Greedy action: \", gp.predict(invalid_board))\n",
    "    print(\"Optimum action: \", pp.predict(invalid_board))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1960f8-efef-4d8a-a8e7-f2d8a3464244",
   "metadata": {},
   "source": [
    "### Verifico también que las estrategias funcionen bien con un tablero valido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c7fd443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random action:  (2, 0)\n",
      "Greedy action:  (2, 0)\n",
      "Optimum action:  (2, 0)\n",
      "\n",
      "Random action:  (1, 3)\n",
      "Greedy action:  (2, 0)\n",
      "Optimum action:  (2, 0)\n",
      "\n",
      "Random action:  (1, 3)\n",
      "Greedy action:  (2, 0)\n",
      "Optimum action:  (2, 0)\n",
      "\n",
      "Random action:  (2, 0)\n",
      "Greedy action:  (2, 0)\n",
      "Optimum action:  (2, 0)\n",
      "\n",
      "Random action:  (2, 0)\n",
      "Greedy action:  (2, 0)\n",
      "Optimum action:  (2, 0)\n",
      "\n",
      "Random action:  (1, 3)\n",
      "Greedy action:  (2, 0)\n",
      "Optimum action:  (2, 0)\n",
      "\n",
      "Random action:  (1, 3)\n",
      "Greedy action:  (2, 0)\n",
      "Optimum action:  (2, 0)\n",
      "\n",
      "Random action:  (1, 3)\n",
      "Greedy action:  (2, 0)\n",
      "Optimum action:  (2, 0)\n",
      "\n",
      "Random action:  (0, 2)\n",
      "Greedy action:  (2, 0)\n",
      "Optimum action:  (2, 0)\n",
      "\n",
      "Random action:  (1, 3)\n",
      "Greedy action:  (2, 0)\n",
      "Optimum action:  (2, 0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "board = np.array([\n",
    "    [ 1,  0,  0, 0],\n",
    "    [-1,  1, -1, 0],\n",
    "    [ 0, -1,  1, 0],\n",
    "    [-1,  1,  0, 0]]\n",
    ")\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"Random action: \", rp.predict(board))\n",
    "    print(\"Greedy action: \", gp.predict(board))\n",
    "    print(\"Optimum action: \", pp.predict(board))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90eca105-9af9-4c23-97fd-110f229ca220",
   "metadata": {},
   "source": [
    "### Verifico que jueguen bien como player 2 (-1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a81addb-2dc0-448d-aea1-39d3d825e290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random action:  (2, 3)\n",
      "Greedy action:  (2, 3)\n",
      "Optimum action:  (0, 3)\n",
      "\n",
      "Random action:  (0, 1)\n",
      "Greedy action:  (0, 1)\n",
      "Optimum action:  (0, 3)\n",
      "\n",
      "Random action:  (0, 3)\n",
      "Greedy action:  (2, 3)\n",
      "Optimum action:  (0, 3)\n",
      "\n",
      "Random action:  (0, 1)\n",
      "Greedy action:  (2, 3)\n",
      "Optimum action:  (0, 3)\n",
      "\n",
      "Random action:  (0, 3)\n",
      "Greedy action:  (0, 3)\n",
      "Optimum action:  (0, 3)\n",
      "\n",
      "Random action:  (0, 1)\n",
      "Greedy action:  (0, 1)\n",
      "Optimum action:  (0, 3)\n",
      "\n",
      "Random action:  (2, 3)\n",
      "Greedy action:  (0, 3)\n",
      "Optimum action:  (0, 3)\n",
      "\n",
      "Random action:  (2, 3)\n",
      "Greedy action:  (2, 3)\n",
      "Optimum action:  (0, 3)\n",
      "\n",
      "Random action:  (0, 3)\n",
      "Greedy action:  (2, 3)\n",
      "Optimum action:  (0, 3)\n",
      "\n",
      "Random action:  (0, 1)\n",
      "Greedy action:  (0, 3)\n",
      "Optimum action:  (0, 3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "board = np.array([\n",
    "    [ 0,  0,  0, 0],\n",
    "    [ 0,  1,  1, 1],\n",
    "    [ 0, -1,  1, 0],\n",
    "    [ 0,  0,  0, 0]]\n",
    ")\n",
    "\n",
    "rp.player = gp.player = pp.player = -1\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"Random action: \", rp.predict(board))\n",
    "    print(\"Greedy action: \", gp.predict(board))\n",
    "    print(\"Optimum action: \", pp.predict(board))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bd5936",
   "metadata": {},
   "source": [
    "# Completar la función que dado dos jugadores imprima estadísticas de las partidas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1162cc5d-642e-4e73-8ae3-e10187af4c2b",
   "metadata": {},
   "source": [
    "Por ejemplo:\n",
    "(Las estadísticas son relativas el que se pasa primero en la función)\n",
    "\n",
    "Wins as first: 0.35\n",
    "\n",
    "Wins as second: 0.55\n",
    "\n",
    "Plays as first: 2457\n",
    "\n",
    "Plays as second: 2543\n",
    "\n",
    "Avg game duration: 5.937"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d773f207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arena_stats(Player_1, Player_2, board_shape, N=500):\n",
    "    \n",
    "    env = ReversiEnv(board_shape=board_shape)\n",
    "    wins_as_first = 0\n",
    "    wins_as_second = 0\n",
    "    ties = 0\n",
    "    plays_as_first = 0\n",
    "    plays_as_second = 0\n",
    "    total_steps = 0\n",
    "    player_1 = Player_1(player=1, board_shape=board_shape, flatten_action=False)\n",
    "    player_2 = Player_2(player=-1, board_shape=board_shape, flatten_action=False)\n",
    "    for i in range(N):\n",
    "        # Aveces empieza un jugador, a veces el otro\n",
    "        first_player = np.random.choice([-1, 1])\n",
    "        player_1.player = first_player\n",
    "        player_2.player = -first_player\n",
    "        \n",
    "        plays_as_first = plays_as_first + (first_player == 1)\n",
    "        plays_as_second = plays_as_second + (first_player == -1)\n",
    "        \n",
    "        done = False\n",
    "        n_steps = 0\n",
    "        (board, player) = env.reset()\n",
    "        \n",
    "        while not done:\n",
    "            if first_player == player:\n",
    "                action = player_1.predict(board)\n",
    "            else:\n",
    "                action = player_2.predict(board)\n",
    "            (board, player), reward, done, info = env.step(action)\n",
    "            n_steps = n_steps + 1\n",
    "        total_steps = total_steps + n_steps\n",
    "        wins_as_first = wins_as_first + (reward == first_player) * (first_player == 1)\n",
    "        wins_as_second = wins_as_second + (reward == first_player) * (first_player == -1)\n",
    "        ties = ties + (reward == 0)\n",
    "    print(f'Wins as first: {wins_as_first/plays_as_first}')\n",
    "    print(f'Wins as second: {wins_as_second/plays_as_second}')\n",
    "    print(f'Ties: {ties/N}')\n",
    "    print(f'Plays as first: {plays_as_first}')\n",
    "    print(f'Plays as second: {plays_as_second}')\n",
    "    print(f'Avg game duration: {total_steps/N}')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5686be83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wins as first: 0.8404040404040404\n",
      "Wins as second: 1.0\n",
      "Ties: 0.0\n",
      "Plays as first: 990\n",
      "Plays as second: 1010\n",
      "Avg game duration: 11.722\n"
     ]
    }
   ],
   "source": [
    "arena_stats(DictPolicyPlayer, GreedyPlayer, 4, N=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1904c487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wins as first: 0.772635814889336\n",
      "Wins as second: 1.0\n",
      "Ties: 0.024\n",
      "Plays as first: 497\n",
      "Plays as second: 503\n",
      "Avg game duration: 11.669\n"
     ]
    }
   ],
   "source": [
    "arena_stats(DictPolicyPlayer, RandomPlayer, 4, N=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17a62f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wins as first: 0.0\n",
      "Wins as second: 0.12573673870333987\n",
      "Ties: 0.018\n",
      "Plays as first: 491\n",
      "Plays as second: 509\n",
      "Avg game duration: 11.637\n"
     ]
    }
   ],
   "source": [
    "arena_stats(RandomPlayer, DictPolicyPlayer, 4, N=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9dec900e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wins as first: 0.4085603112840467\n",
      "Wins as second: 0.5493827160493827\n",
      "Ties: 0.09\n",
      "Plays as first: 514\n",
      "Plays as second: 486\n",
      "Avg game duration: 11.658\n"
     ]
    }
   ],
   "source": [
    "arena_stats(RandomPlayer, GreedyPlayer, 4, N=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4e3ffa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wins as first: 0.34051724137931033\n",
      "Wins as second: 0.5783582089552238\n",
      "Ties: 0.108\n",
      "Plays as first: 232\n",
      "Plays as second: 268\n",
      "Avg game duration: 11.73\n"
     ]
    }
   ],
   "source": [
    "arena_stats(RandomPlayer, RandomPlayer, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60444af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wins as first: 0.42105263157894735\n",
      "Wins as second: 0.525691699604743\n",
      "Ties: 0.072\n",
      "Plays as first: 247\n",
      "Plays as second: 253\n",
      "Avg game duration: 11.64\n"
     ]
    }
   ],
   "source": [
    "arena_stats(GreedyPlayer, GreedyPlayer, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27a12a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wins as first: 0.374\n",
      "Wins as second: 0.352\n",
      "Ties: 0.036\n",
      "Plays as first: 500\n",
      "Plays as second: 500\n",
      "Avg game duration: 57.157\n"
     ]
    }
   ],
   "source": [
    "arena_stats(RandomPlayer, GreedyPlayer, 8, N=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3afc518d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wins as first: 0.59375\n",
      "Wins as second: 0.5557692307692308\n",
      "Ties: 0.054\n",
      "Plays as first: 480\n",
      "Plays as second: 520\n",
      "Avg game duration: 58.177\n"
     ]
    }
   ],
   "source": [
    "arena_stats(GreedyPlayer, RandomPlayer, 8, N=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3d8e40",
   "metadata": {},
   "source": [
    "# Guardar todas las clases de jugadores en un player.py para que luego se puedan importar de la siguiente forma:\n",
    "\n",
    "from players import RandomPlayer\n",
    "\n",
    "from players import GreedyPlayer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
